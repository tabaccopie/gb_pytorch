{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:05.476059Z","iopub.execute_input":"2022-06-01T06:19:05.476443Z","iopub.status.idle":"2022-06-01T06:19:15.102904Z","shell.execute_reply.started":"2022-06-01T06:19:05.476395Z","shell.execute_reply":"2022-06-01T06:19:15.101847Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"Необходимо подготовить датасет https://www.kaggle.com/olekslu/makeup-lips-segmentation-28k-samples для обучения модели на сегментацию губ\n\nОбучить модель на выбор из segmentation_models_pytorchfiles_names_list = sorted(os.listdir(images_path))","metadata":{}},{"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nfrom pathlib import Path\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nimport cv2\n\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.105304Z","iopub.execute_input":"2022-06-01T06:19:15.105775Z","iopub.status.idle":"2022-06-01T06:19:15.113644Z","shell.execute_reply.started":"2022-06-01T06:19:15.105702Z","shell.execute_reply":"2022-06-01T06:19:15.112737Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"dataset_file = '/kaggle/input/makeup-lips-segmentation-28k-samples/set-lipstick-original/list.csv'\nimages_path = '/kaggle/input/makeup-lips-segmentation-28k-samples/set-lipstick-original/720p/'\nmasks_path = '/kaggle/input/makeup-lips-segmentation-28k-samples/set-lipstick-original/mask/'","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.115054Z","iopub.execute_input":"2022-06-01T06:19:15.115722Z","iopub.status.idle":"2022-06-01T06:19:15.128371Z","shell.execute_reply.started":"2022-06-01T06:19:15.115684Z","shell.execute_reply":"2022-06-01T06:19:15.127466Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(dataset_file)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.131223Z","iopub.execute_input":"2022-06-01T06:19:15.132010Z","iopub.status.idle":"2022-06-01T06:19:15.204751Z","shell.execute_reply.started":"2022-06-01T06:19:15.131968Z","shell.execute_reply":"2022-06-01T06:19:15.203863Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"files_names_list = sorted(os.listdir(images_path))\nmasks_names_list = sorted(os.listdir(masks_path))\nprint(f'Images {len(files_names_list)}')\nprint(f'Masks {len(masks_names_list)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.206201Z","iopub.execute_input":"2022-06-01T06:19:15.206602Z","iopub.status.idle":"2022-06-01T06:19:15.259785Z","shell.execute_reply.started":"2022-06-01T06:19:15.206564Z","shell.execute_reply":"2022-06-01T06:19:15.258916Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#почистим лист -- уберем строки с файлами без масок\ndf = df.loc[df['mask'].isin([i for i in masks_names_list])]\ndf = df.loc[df['filename'].isin([i for i in files_names_list])]\ndf.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.261171Z","iopub.execute_input":"2022-06-01T06:19:15.261714Z","iopub.status.idle":"2022-06-01T06:19:15.302804Z","shell.execute_reply.started":"2022-06-01T06:19:15.261676Z","shell.execute_reply":"2022-06-01T06:19:15.301843Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#посмотрим данные\nimage = cv2.imread(images_path + files_names_list[11], cv2.COLOR_BGR2RGB)\nmask = cv2.imread(masks_path + masks_names_list[11], cv2.COLOR_BGR2RGB)\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 10))\nax[0].imshow(image)\nax[0].set_title(f'Изображение {image.shape}')\nax[1].imshow(mask)\nax[1].set_title(f'Маска {mask.shape}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.304500Z","iopub.execute_input":"2022-06-01T06:19:15.304995Z","iopub.status.idle":"2022-06-01T06:19:15.809277Z","shell.execute_reply.started":"2022-06-01T06:19:15.304946Z","shell.execute_reply":"2022-06-01T06:19:15.808369Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"data = df[['filename', 'mask']]\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.811162Z","iopub.execute_input":"2022-06-01T06:19:15.813936Z","iopub.status.idle":"2022-06-01T06:19:15.825262Z","shell.execute_reply.started":"2022-06-01T06:19:15.813892Z","shell.execute_reply":"2022-06-01T06:19:15.824273Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.827083Z","iopub.execute_input":"2022-06-01T06:19:15.827506Z","iopub.status.idle":"2022-06-01T06:19:15.837634Z","shell.execute_reply.started":"2022-06-01T06:19:15.827468Z","shell.execute_reply":"2022-06-01T06:19:15.836694Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"#инициализация модели\nsegmodel = smp.Linknet(encoder_name = 'resnet34', \n                    encoder_weights = 'imagenet', \n                    in_channels = 3, \n                    classes = 1, # число каналов маски\n                    activation = 'sigmoid').to(device)\n\npreprocess_input = smp.encoders.get_preprocessing_fn('resnet34', pretrained='imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:15.840688Z","iopub.execute_input":"2022-06-01T06:19:15.841222Z","iopub.status.idle":"2022-06-01T06:19:16.423157Z","shell.execute_reply.started":"2022-06-01T06:19:15.841192Z","shell.execute_reply":"2022-06-01T06:19:16.422214Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"#класс датасета\nclass CustomDataset(Dataset):\n    def __init__(self, data, preprocessing=None):\n        # загружаем данные из датасета\n        self.data = data\n        self.preprocessing = preprocessing\n        self.image_arr = self.data.iloc[:,0] # имена файлов картинок из датасета\n        self.label_arr = self.data.iloc[:,1] # имена файлов масок из датасета\n        self.data_len = len(self.data.index)\n        \n    def __len__(self):\n        return self.data_len\n        \n    def __getitem__(self, index):\n       # загружаем картинки\n        img = cv2.imread(images_path+self.image_arr[index]) \n        img = cv2.cvtColor(cv2.resize(img, (256, 256)), cv2.COLOR_BGR2RGB)\n        img = np.asarray(img).astype('float')\n        \n        if self.preprocessing:\n            img = self.preprocessing(img)\n            img = torch.as_tensor(img)\n        \n        else:\n            img = torch.as_tensor(img)\n            img /= 255.0\n        \n        img = img.permute(2,0,1)\n        \n        # загружаем маски\n        mask = cv2.imread(masks_path+self.label_arr[index])\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)        \n        cls_mask = np.where(mask > 50, 1, 0)[:,:,1]\n        cls_mask = cls_mask.astype('float')\n        cls_mask = cv2.resize(cls_mask, (256, 256))\n\n        masks = [cls_mask]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        \n        \n        return (img.float(), masks)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:16.424751Z","iopub.execute_input":"2022-06-01T06:19:16.425171Z","iopub.status.idle":"2022-06-01T06:19:16.439136Z","shell.execute_reply.started":"2022-06-01T06:19:16.425116Z","shell.execute_reply":"2022-06-01T06:19:16.437805Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"#разделение датасета на train и test\nX_train, X_test = train_test_split(data, test_size=0.3, random_state=42)\n\n#сбрасываем индексы\nX_train.reset_index(drop=True,inplace=True)\nX_test.reset_index(drop=True,inplace=True)\n\n#создаем датасеты\ntrain_data = CustomDataset(X_train, preprocessing=preprocess_input)\ntest_data = CustomDataset(X_test, preprocessing=preprocess_input)\n\n#создаем даталодеры\ntrain_data_loader = DataLoader(train_data, batch_size=8, shuffle=True)\ntest_data_loader = DataLoader(test_data, batch_size=4, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:16.440938Z","iopub.execute_input":"2022-06-01T06:19:16.441670Z","iopub.status.idle":"2022-06-01T06:19:16.460144Z","shell.execute_reply.started":"2022-06-01T06:19:16.441624Z","shell.execute_reply":"2022-06-01T06:19:16.459100Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"#просмотр данных из даталоадера\nfor img, target in train_data_loader:\n    print(img.shape, target.shape)\n    print(img[0].min(), img[0].max())\n    print(target[0].min(), target[0].max())\n    fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n    ax[0].imshow(img[0].permute(1, 2, 0))\n    ax[1].imshow(target[0].permute(1, 2, 0)[..., 0])\n    break","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:16.462067Z","iopub.execute_input":"2022-06-01T06:19:16.462522Z","iopub.status.idle":"2022-06-01T06:19:17.241187Z","shell.execute_reply.started":"2022-06-01T06:19:16.462480Z","shell.execute_reply":"2022-06-01T06:19:17.239556Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"#определение критерия, метрики и оптимизатора\ncriterion = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU(),]\noptimizer = torch.optim.Adam(params=segmodel.parameters(), lr=0.001)\n\n#определение тренировочных и валидационных эпох\ntrain_epoch = smp.utils.train.TrainEpoch(\n    segmodel, \n    loss=criterion, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    segmodel, \n    loss=criterion, \n    metrics=metrics,\n    device=device,\n    verbose=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:17.242613Z","iopub.execute_input":"2022-06-01T06:19:17.243061Z","iopub.status.idle":"2022-06-01T06:19:17.260204Z","shell.execute_reply.started":"2022-06-01T06:19:17.243022Z","shell.execute_reply":"2022-06-01T06:19:17.259270Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# обучение модели\nnum_epochs = 10\nlinknet_train_iou = []\nlinknet_valid_iou = []\n\nfor i in range(num_epochs):\n    print(f'Epoch: {i + 1}')\n    train_logs = train_epoch.run(train_data_loader)\n    valid_logs = valid_epoch.run(test_data_loader)\n    \n    linknet_train_iou.append(train_logs['iou_score'])\n    linknet_valid_iou.append(valid_logs['iou_score'])","metadata":{"execution":{"iopub.status.busy":"2022-06-01T06:19:17.261614Z","iopub.execute_input":"2022-06-01T06:19:17.262247Z","iopub.status.idle":"2022-06-01T10:36:12.768824Z","shell.execute_reply.started":"2022-06-01T06:19:17.262204Z","shell.execute_reply":"2022-06-01T10:36:12.768041Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"x = np.arange(1,11,1)\ny = linknet_train_iou\ny2 = linknet_valid_iou\n\nplt.plot(x,y,label='IOU_train')\nplt.plot(x,y2,label='IOU_val')\n\nplt.title(f\"Linknet\")   \nplt.ylabel('IOU_score')   \nplt.xlabel('epochs')   \nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:40:35.956240Z","iopub.execute_input":"2022-06-01T10:40:35.956610Z","iopub.status.idle":"2022-06-01T10:40:36.256990Z","shell.execute_reply.started":"2022-06-01T10:40:35.956572Z","shell.execute_reply":"2022-06-01T10:40:36.247342Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"#предсказание модели\nfor i, data in enumerate(test_data_loader):\n    images, labels = data\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    outputs = segmodel(images)\n    \n    f, axarr = plt.subplots(1,3, figsize=(15, 6))\n\n    for j in range(0, 4):\n        axarr[0].imshow(outputs.detach().cpu()[i, ].permute(1, 2, 0))\n        axarr[0].set_title('Guessed labels')\n        \n        axarr[1].imshow(labels[i, ].cpu().permute(1, 2, 0))\n        axarr[1].set_title('Ground truth labels')\n        \n        image = images[i].permute(1, 2, 0)\n        axarr[2].imshow(image.cpu())\n        axarr[2].set_title('Original Images')\n        plt.show()\n    if i > 2:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-06-01T10:47:40.775960Z","iopub.execute_input":"2022-06-01T10:47:40.776306Z","iopub.status.idle":"2022-06-01T10:47:43.351197Z","shell.execute_reply.started":"2022-06-01T10:47:40.776277Z","shell.execute_reply":"2022-06-01T10:47:43.350453Z"},"trusted":true},"execution_count":90,"outputs":[]}]}